{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "*Any_Face_Clustering_Streamlit_app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMd31MSA8pbFhnnzsOyDDGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souvikmajumder26/Any-Face-Clustering/blob/main/Any_Face_Clustering_Streamlit_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Follow these Steps to reach the Streamlit Web App (with this google colab notebook as the backend)** :\n",
        "> ### **1)** *In the above Menu bar, choose Runtime -> Change Runtime type -> Hardware Accelerator -> GPU -> Save*\n",
        "> ### **2)** *Run the below 3 cells sequentially. A reminder appears as the notebook is located in a GitHub Repository instead of your Drive, Click on \"Run Anyway\".*\n",
        "> ### **3)** *Click on the URL (eg: ...loca.it) produced as output by the last cell while the last cell continues to run here.*\n",
        "> ### **4)** *On opening the URL, a Friendly Reminder is shown informing that this website is being hosted by a localtunnel; click on \"Click to Continue\" because we know exactly who is hosting the website: our own Google Colab notebook.*\n",
        "> ### **5)** *And... you have landed on the Streamlit App; sometimes it might show \"Please Wait...\" for a long time before the app comes live... just wait and keep this collab notebook and the web app running.*\n",
        "\n",
        "### **OR**, download the notebook code and run the Streamlit Web App on your local machine.\n",
        "\n",
        "**Feel free to interact with the web app... Upload images of several faces (make sure to upload atleast 3 images containing the same face)... or you can choose to use the <a href=\"https://drive.google.com/drive/folders/1JXYCf4Qk4fuTfTDoduGU7vgmXNyXSMUe?usp=sharing\">*Unlabelled_test_images*</a> by downloading the folder and then uploading the images to the Web App to experience how the project works.**"
      ],
      "metadata": {
        "id": "nmAmjaeUvV0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition\n",
        "!pip install -q streamlit\n",
        "# If ipykernel & ipython version related warnings are shown while installing streamlit: IGNORE"
      ],
      "metadata": {
        "id": "C__Z0EwvIPbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit-app.py\n",
        "\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "\n",
        "import cv2\n",
        "import face_recognition\n",
        "from sklearn.cluster import DBSCAN\n",
        "from imutils import build_montages\n",
        "\n",
        "flag1 = 0\n",
        "\n",
        "st.set_page_config(layout = 'wide')\n",
        "\n",
        "#st.title(\"Any Face Clustering\")\n",
        "st.markdown(\"<h1 style='text-align: center; color: grey;'>Any Face Clustering</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "st.text(\" \")\n",
        "st.text(\"Upload Images of Multiple Faces (with AT LEAST 3 images of a particular face).\")\n",
        "st.text(\"Please wait a while after uploading the images until you see a dialog box stating that the images were uploaded successfully.\")\n",
        "st.text(\"Sometimes Streamlit takes unusually more time to upload the images... if failed, try compressing the images before uploading.\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"\", type = [\"png\",\"jpg\",\"jpeg\"], accept_multiple_files = True)\n",
        "\n",
        "no_of_files = len(uploaded_files)\n",
        "\n",
        "if no_of_files > 0:\n",
        "  placeholder = st.empty()\n",
        "  placeholder.success(\"{} Images uploaded successfully!\".format(no_of_files))\n",
        "  time.sleep(3)\n",
        "  placeholder.empty()\n",
        "  data = []\n",
        "  \n",
        "  for f in uploaded_files:\n",
        "    tfile = tempfile.NamedTemporaryFile(delete = False)\n",
        "    tfile.write(f.read())\n",
        "    image = cv2.imread(tfile.name)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    d = [{\"imagePath\": tfile.name, \"loc\": box, \"encoding\": enc} for (box, enc) in zip(boxes, encodings)]\n",
        "    data.extend(d)\n",
        "  \n",
        "  # converting the data into a numpy array\n",
        "  data_arr = np.array(data)\n",
        "  # extracting the 128-d facial encodings and placing them in a list\n",
        "  encodings_arr = [item[\"encoding\"] for item in data_arr]\n",
        "\n",
        "  # initializing and fitting the clustering model on the encoded data\n",
        "  cluster = DBSCAN(min_samples = 3)\n",
        "  cluster.fit(encodings_arr)\n",
        "  st.balloons()\n",
        "  \n",
        "  labelIDs = np.unique(cluster.labels_)\n",
        "  numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
        "  \n",
        "  st.subheader(\"Number of unique faces identified (excluding the unknown faces) is: \" + str(numUniqueFaces))\n",
        "\n",
        "  if flag1 == 0:\n",
        "    cols1 = st.columns(numUniqueFaces + 1)\n",
        "    flag1 = 1\n",
        "\n",
        "  # loop over the unique face integers\n",
        "  for labelID in labelIDs:\n",
        "    idxs = np.where(cluster.labels_ == labelID)[0]\n",
        "    idxs = np.random.choice(idxs, size = min(15, len(idxs)), replace = False)\n",
        "    # initializing the list of faces to include in the montage\n",
        "    faces = []\n",
        "    # initializing the list of whole_images to include in the zip files of each faces, to be downloaded by the user\n",
        "    whole_images = []\n",
        "    \n",
        "    if labelID != -1:\n",
        "      dir_name = 'face#{}'.format(labelID + 1)\n",
        "      os.mkdir(dir_name)\n",
        "\n",
        "    for i in idxs:\n",
        "      current_image = cv2.imread(data_arr[i][\"imagePath\"])\n",
        "      rgb_current_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2RGB)\n",
        "      (top, right, bottom, left) = data_arr[i][\"loc\"]\n",
        "      current_face = rgb_current_image[top:bottom, left:right]\n",
        "      current_face = cv2.resize(current_face, (96, 96))\n",
        "      whole_images.append(rgb_current_image)\n",
        "      faces.append(current_face)\n",
        "\n",
        "      if labelID != -1:\n",
        "        face_image_name = 'image{}.jpg'.format(i)\n",
        "        cv2.imwrite(os.path.join(dir_name, face_image_name), current_image)\n",
        "    \n",
        "    if labelID != -1:\n",
        "      shutil.make_archive('zip_face#{}'.format(labelID + 1), 'zip', dir_name)\n",
        "      # deleting the directory and image files contained in it as we need only the zip file which has been created already\n",
        "      shutil.rmtree('face#{}'.format(labelID + 1))\n",
        "      \n",
        "    montage = build_montages(faces, (96, 96), (2, 2))[0]\n",
        "\n",
        "    current_title = \"Face #{}:\".format(labelID + 1)\n",
        "    expander_caption = \"Images with Face #{}:\".format(labelID + 1)\n",
        "    current_title = \"Unknown:\" if labelID == -1 else current_title\n",
        "\n",
        "    with cols1[labelID + 1]:\n",
        "      st.write(current_title)\n",
        "      st.image(montage)\n",
        "    if labelID != -1:\n",
        "      with st.expander(expander_caption):\n",
        "        # displaying the images of the current face\n",
        "        cols2 = st.columns(3)\n",
        "        for j in range(len(whole_images)):\n",
        "          with cols2[j%3]:\n",
        "            st.image(whole_images[j], use_column_width = 'always')\n",
        "        # providing an option for the user to download folders with images of particular faces after clustering as zip files\n",
        "        with open(\"zip_face#{}.zip\".format(labelID + 1), \"rb\") as fp:\n",
        "          btn = st.download_button(\n",
        "              label=\"Download ZIP of Clustered Images with Face #{}\".format(labelID + 1),\n",
        "              data=fp,\n",
        "              file_name=\"clustered_faces#{}.zip\".format(labelID + 1),\n",
        "              mime=\"application/zip\"\n",
        "          )\n",
        "        fp.close()"
      ],
      "metadata": {
        "id": "9Uu-QAGW1ApU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit-app.py & npx localtunnel --port 8501 --server.enableCORS = false --server.enableXsrfProtection = false"
      ],
      "metadata": {
        "id": "FCuFtBZLW7vc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}