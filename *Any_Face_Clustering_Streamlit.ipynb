{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "*Any_Face_Clustering_Streamlit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCMiN5u8JqNOym8UiaE309",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souvikmajumder26/Any-Face-Clustering/blob/main/*Any_Face_Clustering_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition\n",
        "!pip install -q streamlit\n",
        "# If ipykernel & ipython version related warnings are shown while installing streamlit: IGNORE"
      ],
      "metadata": {
        "id": "C__Z0EwvIPbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit-app.py\n",
        "\n",
        "import cv2\n",
        "import face_recognition\n",
        "\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from imutils import build_montages\n",
        "#from zipfile import ZipFile\n",
        "\n",
        "flag1 = 0\n",
        "\n",
        "st.set_page_config(layout = 'wide')\n",
        "\n",
        "st.title(\"Any Face Clustering\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload Images of Multiple Faces (with AT LEAST 3 images of a particular face):\", type = [\"png\",\"jpg\",\"jpeg\"], accept_multiple_files = True)\n",
        "\n",
        "no_of_files = len(uploaded_files)\n",
        "\n",
        "if no_of_files>0:\n",
        "  placeholder = st.empty()\n",
        "  placeholder.success(\"{} Images uploaded successfully!\".format(no_of_files))\n",
        "  time.sleep(3)\n",
        "  placeholder.empty()\n",
        "  data = []\n",
        "  \n",
        "  for f in uploaded_files:\n",
        "    tfile = tempfile.NamedTemporaryFile(delete = False)\n",
        "    tfile.write(f.read())\n",
        "    image = cv2.imread(tfile.name)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    #st.write(rgb)\n",
        "    #st.image(rgb)\n",
        "    boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    #st.write(boxes)\n",
        "    #st.write(encodings)\n",
        "    d = [{\"imagePath\": tfile.name, \"loc\": box, \"encoding\": enc} for (box, enc) in zip(boxes, encodings)]\n",
        "    data.extend(d)\n",
        "  \n",
        "  # converting the data into a numpy array\n",
        "  data_arr = np.array(data)\n",
        "  # extracting the 128-d facial encodings and placing them in a list\n",
        "  encodings_arr = [item[\"encoding\"] for item in data_arr]\n",
        "\n",
        "  # initializing and fitting the clustering model on the encoded data\n",
        "  cluster = DBSCAN(min_samples = 3)\n",
        "  cluster.fit(encodings_arr)\n",
        "  st.balloons()\n",
        "  #st.write(data)\n",
        "  #st.write(data_arr)\n",
        "  #st.write(np.shape(encodings_arr))\n",
        "  #st.write(encodings_arr)  \n",
        "  #st.write(\"Model Fit: SUCCESS\")\n",
        "  #st.write(cluster.n_features_in_)\n",
        "  #st.write(cluster.labels_)\n",
        "  \n",
        "  labelIDs = np.unique(cluster.labels_)\n",
        "  numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
        "  \n",
        "  st.subheader(\"Number of unique faces identified (excluding the unknown faces) is: \" + str(numUniqueFaces))\n",
        "  #st.write(labelIDs)\n",
        "\n",
        "  if flag1 == 0:\n",
        "    cols1 = st.columns(numUniqueFaces + 1)\n",
        "    flag1 = 1\n",
        "  \n",
        "  #cols2 = st.columns(2)\n",
        "\n",
        "  # loop over the unique face integers\n",
        "  for labelID in labelIDs:\n",
        "    # find all indexes into the 'pkl_data' array that belong to the current label ID, then randomly sample a maximum of 15 indexes from the set\n",
        "    #print(\"[INFO] faces for face ID: {}\".format(labelID))\n",
        "    idxs = np.where(cluster.labels_ == labelID)[0]\n",
        "    idxs = np.random.choice(idxs, size = min(15, len(idxs)), replace = False)\n",
        "    # initialize the list of faces to include in the montage\n",
        "    faces = []\n",
        "    whole_images = []\n",
        "    \n",
        "    if labelID != -1:\n",
        "      dir_name = 'face#{}'.format(labelID + 1)\n",
        "      os.mkdir(dir_name)\n",
        "\n",
        "    for i in idxs:\n",
        "      # load the input image and extract the face ROI\n",
        "      current_image = cv2.imread(data_arr[i][\"imagePath\"])\n",
        "      rgb_current_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2RGB)\n",
        "      (top, right, bottom, left) = data_arr[i][\"loc\"]\n",
        "      current_face = rgb_current_image[top:bottom, left:right]\n",
        "      # force resize the face ROI to 96x96 and then add it to the faces montage list\n",
        "      current_face = cv2.resize(current_face, (96, 96))\n",
        "      whole_images.append(rgb_current_image)\n",
        "      faces.append(current_face)\n",
        "\n",
        "      if labelID != -1:\n",
        "        face_image_name = 'image{}.jpg'.format(i)\n",
        "        cv2.imwrite(os.path.join(dir_name, face_image_name), current_image)\n",
        "    \n",
        "    if labelID != -1:\n",
        "      shutil.make_archive('zip_face#{}'.format(labelID + 1), 'zip', dir_name)\n",
        "      # deleting the directory and image files contained in it\n",
        "      shutil.rmtree('face#{}'.format(labelID + 1))\n",
        "      \n",
        "    # create a montage using 96x96 \"tiles\" with 5 rows and 5 columns\n",
        "    montage = build_montages(faces, (96, 96), (3, 3))[0]\n",
        "    \n",
        "    #if labelID != -1:\n",
        "      #zip_obj = ZipFile(\"faces#{}.zip\".format(labelID + 1), \"w\")\n",
        "      # add multiple images to the zip\n",
        "      #for current_whole_image in whole_images:\n",
        "        #zip_obj.write(current_whole_image)\n",
        "      # close the Zip File\n",
        "      #zip_obj.close()\n",
        "\n",
        "    # show the output montage\n",
        "    current_title = \"Face #{}:\".format(labelID + 1)\n",
        "    expander_caption = \"Images with Face #{}:\".format(labelID + 1)\n",
        "    current_title = \"Unknown:\" if labelID == -1 else current_title\n",
        "    #expander_caption = \"Images with Unknown Faces:\" if labelID == -1 else expander_caption\n",
        "    #cv2_imshow(montage)\n",
        "    with cols1[labelID + 1]:\n",
        "      st.write(current_title)\n",
        "      st.image(montage)\n",
        "    if labelID != -1:\n",
        "      with st.expander(expander_caption):\n",
        "        with open(\"zip_face#{}.zip\".format(labelID + 1), \"rb\") as fp:\n",
        "          btn = st.download_button(\n",
        "              label=\"Download ZIP of Clustered Images with Face#{}\".format(labelID + 1),\n",
        "              data=fp,\n",
        "              file_name=\"clustered_faces#{}.zip\".format(labelID + 1),\n",
        "              mime=\"application/zip\"\n",
        "          )\n",
        "        fp.close()\n",
        "        #st.download_button(\"Download images with Face #{}\".format(labelID + 1), data = 'faces#{}.zip'.format(labelID + 1))\n",
        "        cols2 = st.columns(3)\n",
        "        for j in range(len(whole_images)):\n",
        "          with cols2[j%3]:\n",
        "            st.image(whole_images[j], use_column_width = 'always')        "
      ],
      "metadata": {
        "id": "9Uu-QAGW1ApU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit-app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "FCuFtBZLW7vc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}